name: ci
on: [push, pull_request]
jobs:
  lint:
    runs-on: ubuntu-22.04
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with: {python-version: '3.11'}
    - run: pip install ruff
    - run: ruff --version
    - run: ruff check .

  test-cpu:
    runs-on: ubuntu-22.04
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with: {python-version: '3.11'}
    - run: pip install -e .[cpu,dev] -f https://download.pytorch.org/whl/cpu/torch_stable.html
    - run: pytest -q -m "not gpu" --maxfail=1

  test-gpu:
    runs-on: [self-hosted, gpu]
    defaults:
      run:
        shell: powershell
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with: {python-version: '3.11'}

    - name: Install PyTorch CUDA 12.1
      run: |
        python -m pip install --upgrade pip
        python -m pip install --index-url https://download.pytorch.org/whl/cu121 `
          torch==2.3.* torchvision==0.18.* torchaudio==2.3.*

    - name: Install project (cuda + dev)
      run: python -m pip install -e .[cuda,dev]

    - name: CUDA availability gate
      run: |
        python -c "import torch;print('torch',torch.__version__);print('cuda',getattr(torch.version,'cuda',None));print('avail',torch.cuda.is_available());print('n',torch.cuda.device_count());assert torch.cuda.is_available()" `
        | Tee-Object -FilePath env.txt

    - name: Run GPU-marked tests
      run: |
        python -m pytest -q -m gpu -k "frames or sources or solvers or io or validation" --maxfail=1 `
        | Tee-Object -FilePath pytest_gpu.log

    - name: Upload artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: gpu-smoke-artifacts
        path: |
          env.txt
          pytest_gpu.log


